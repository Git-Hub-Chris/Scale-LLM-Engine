{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate fine-tuning open source models in order to classify emails into two categories, based on their content.\n",
    "\n",
    "We will prepare 950 examples to fine-tune on, and use 50 examples to test the performance of our fine-tune. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "\n",
    "categories = ['rec.sport.baseball', 'rec.sport.hockey']\n",
    "sports_dataset = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories)\n",
    "\n",
    "labels = [sports_dataset.target_names[x].split('.')[-1] for x in sports_dataset['target']]\n",
    "texts = [text.strip() for text in sports_dataset['data']]\n",
    "df = pd.DataFrame(zip(texts, labels), columns = ['raw_prompt','response'])[:1000]\n",
    "df_train = df[:950]\n",
    "df_test = df[950:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take a look at our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: dougb@comm.mot.com (Doug Bank)\\nSubject: Re: Info needed for Cleveland tickets\\nReply-To: dougb@ecs.comm.mot.com\\nOrganization: Motorola Land Mobile Products Sector\\nDistribution: usa\\nNntp-Posting-Host: 145.1.146.35\\nLines: 17\\n\\nIn article <1993Apr1.234031.4950@leland.Stanford.EDU>, bohnert@leland.Stanford.EDU (matthew bohnert) writes:\\n\\n|> I'm going to be in Cleveland Thursday, April 15 to Sunday, April 18.\\n|> Does anybody know if the Tribe will be in town on those dates, and\\n|> if so, who're they playing and if tickets are available?\\n\\nThe tribe will be in town from April 16 to the 19th.\\nThere are ALWAYS tickets available! (Though they are playing Toronto,\\nand many Toronto fans make the trip to Cleveland as it is easier to\\nget tickets in Cleveland than in Toronto.  Either way, I seriously\\ndoubt they will sell out until the end of the season.)\\n\\n-- \\nDoug Bank                       Private Systems Division\\ndougb@ecs.comm.mot.com          Motorola Communications Sector\\ndougb@nwu.edu                   Schaumburg, Illinois\\ndougb@casbah.acns.nwu.edu       708-576-8207\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['raw_prompt'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "baseball    498\n",
       "hockey      452\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "baseball    25\n",
       "hockey      25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['response'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are training a text generation model, let's do a bit of (extremely basic) prompt engineering to use the model for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(text: str):\n",
    "    return f\"Prompt: {text}\\nCategory: \"\n",
    "\n",
    "def prepare_df(df: pd.DataFrame):\n",
    "    # df['prompt'] = df.apply(lambda row: build_prompt(row['raw_prompt']), axis=1)\n",
    "    df['prompt'] = df['raw_prompt'].apply(build_prompt)\n",
    "    df.drop('raw_prompt', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_df(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseball</td>\n",
       "      <td>Prompt: From: dougb@comm.mot.com (Doug Bank)\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hockey</td>\n",
       "      <td>Prompt: From: gld@cunixb.cc.columbia.edu (Gary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseball</td>\n",
       "      <td>Prompt: From: rudy@netcom.com (Rudy Wade)\\nSub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hockey</td>\n",
       "      <td>Prompt: From: monack@helium.gas.uug.arizona.ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseball</td>\n",
       "      <td>Prompt: Subject: Let it be Known\\nFrom: &lt;ISSBT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   response                                             prompt\n",
       "0  baseball  Prompt: From: dougb@comm.mot.com (Doug Bank)\\n...\n",
       "1    hockey  Prompt: From: gld@cunixb.cc.columbia.edu (Gary...\n",
       "2  baseball  Prompt: From: rudy@netcom.com (Rudy Wade)\\nSub...\n",
       "3    hockey  Prompt: From: monack@helium.gas.uug.arizona.ed...\n",
       "4  baseball  Prompt: Subject: Let it be Known\\nFrom: <ISSBT..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to end up in a CSV file that has two columns: `prompt` and `response`, and that is publicly accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"sports_training_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, we upload our csv to `s3://scale-demo-datasets/sports/sports_training_dataset.csv`, which maps to a URL of `https://scale-demo-datasets.s3.us-west-2.amazonaws.com/sports/sports_training_dataset.csv`. We make sure this is publicly accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to set an environment variable SCALE_API_KEY. \n",
    "#   Since we're in an ipynb, we can do this. Otherwise, you just need to set the environment variable however you need to\n",
    "import dotenv\n",
    "env_file = \".env\"\n",
    "dotenv.load_dotenv(env_file, override=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the fine-tune from our training file via the FineTune API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmengine import FineTune, Completion, Model\n",
    "\n",
    "FineTune.validate_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "create_fine_tune_response = FineTune.create(\n",
    "    model=\"llama-7b\",\n",
    "    training_file=\"https://scale-demo-datasets.s3.us-west-2.amazonaws.com/sports/sports_training_dataset.csv\",\n",
    "    validation_file=None,\n",
    "    hyperparameters={},\n",
    "    suffix=\"my-first-fine-tune\"\n",
    ")\n",
    "\n",
    "fine_tune_id = create_fine_tune_response.fine_tune_id\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for fine tune to complete\n",
    "\n",
    "import time\n",
    "while True:\n",
    "    fine_tune_status = FineTune.retrieve(fine_tune_id).status\n",
    "    print(fine_tune_status)\n",
    "    if fine_tune_status == \"SUCCESS\":\n",
    "        break\n",
    "    elif fine_tune_status in [\"FAILURE\", \"CANCELLED\"]:\n",
    "        raise ValueError(\"Fine Tune failed\")\n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you're running this script for the first time, we can get your fine-tune via looking at all the models available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = Model.list().model_endpoints\n",
    "\n",
    "# We want to get just your fine-tuned models.\n",
    "your_personal_fine_tunes = [model for model in all_models if not model.spec.public_inference]\n",
    "\n",
    "your_fine_tuned_model = your_personal_fine_tunes[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've already created a fine-tune from a previous run, we can also just use that value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-coded value from a previous run of this script\n",
    "your_fine_tuned_model = \"llama-7b.my-first-finetune.2023-07-17-19-44-20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Fine-Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run our model on the test dataset via the Completions API. Since we trained using a prompt template, use that prompt template when making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(prompt: str):\n",
    "    for _ in range(5):\n",
    "        try:\n",
    "            response = Completion.create(model_name=your_fine_tuned_model, prompt=build_prompt(prompt), max_new_tokens=2, temperature=0.01)\n",
    "            return response.outputs[0].text.rstrip(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"predicted_response\"] = df_test[\"raw_prompt\"].apply(get_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's peek at the data and calculate our test accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>predicted_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>From: tedward@cs.cornell.edu (Edward [Ted] Fis...</td>\n",
       "      <td>baseball</td>\n",
       "      <td>baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>From: smorris@venus.lerc.nasa.gov (Ron Morris ...</td>\n",
       "      <td>hockey</td>\n",
       "      <td>hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>From: shah@pitt.edu (Ravindra S Shah)\\nSubject...</td>\n",
       "      <td>hockey</td>\n",
       "      <td>hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>From: timlin@spot.Colorado.EDU (Michael Timlin...</td>\n",
       "      <td>baseball</td>\n",
       "      <td>baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>From: gp2011@andy.bgsu.edu (George Pavlic)\\nSu...</td>\n",
       "      <td>hockey</td>\n",
       "      <td>hockey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_prompt  response  \\\n",
       "950  From: tedward@cs.cornell.edu (Edward [Ted] Fis...  baseball   \n",
       "951  From: smorris@venus.lerc.nasa.gov (Ron Morris ...    hockey   \n",
       "952  From: shah@pitt.edu (Ravindra S Shah)\\nSubject...    hockey   \n",
       "953  From: timlin@spot.Colorado.EDU (Michael Timlin...  baseball   \n",
       "954  From: gp2011@andy.bgsu.edu (George Pavlic)\\nSu...    hockey   \n",
       "\n",
       "    predicted_response  \n",
       "950           baseball  \n",
       "951             hockey  \n",
       "952             hockey  \n",
       "953           baseball  \n",
       "954             hockey  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = len(df_test[df_test[\"predicted_response\"] == (df_test[\"response\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct / len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>predicted_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>From: maX &lt;maX@maxim.rinaco.msk.su&gt;\\nSubject: ...</td>\n",
       "      <td>hockey</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>From: jca2@cec1.wustl.edu (Joseph Charles Achk...</td>\n",
       "      <td>hockey</td>\n",
       "      <td>NHL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>From: apland@mala.bc.ca (Ron Apland)\\nSubject:...</td>\n",
       "      <td>hockey</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_prompt response  \\\n",
       "974  From: maX <maX@maxim.rinaco.msk.su>\\nSubject: ...   hockey   \n",
       "988  From: jca2@cec1.wustl.edu (Joseph Charles Achk...   hockey   \n",
       "997  From: apland@mala.bc.ca (Ron Apland)\\nSubject:...   hockey   \n",
       "\n",
       "    predicted_response  \n",
       "974                     \n",
       "988                NHL  \n",
       "997                     "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test[\"predicted_response\"] != df_test[\"response\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
