{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\u26a1 Spellbook Serve \u26a1","text":"<p>The fastest, cheapest, and easiest way to deploy and scale your custom foundation models.</p>"},{"location":"#quick-install","title":"\ud83d\udcbb Quick Install","text":"Install using pipInstall using conda <pre><code>pip install spellbook-serve-client\n</code></pre> <pre><code>conda install spellbook-serve-client -c conda-forge\n</code></pre>"},{"location":"#about","title":"\ud83e\udd14 About","text":"<p>Foundation models are emerging as the building blocks of AI. However, deploying these models to the cloud still requires infrastructure expertise, and can be expensive.</p> <p>Spellbook Serve is a Python library, CLI, and Helm chart that provides everything you need to deploy your foundation models to the cloud using Kubernetes. Key features include:</p> <p>\ud83d\udc33 Deploying from any docker image: Turn any Docker image into an auto-scaling deployment with simple APIs.</p> <p>\ud83c\udf99\ufe0fLanguage-Model Specific Features: Spellbook Serve provides APIs for streaming responses and dynamically batching inputs for higher throughput and lower latency.</p> <p>\ud83e\udd17 Open-Source Integrations: Deploy any Huggingface model with a single command. Integrate seamlessly with Langchain chat applications.</p>"},{"location":"#features-coming-soon","title":"\ud83d\udd25 Features Coming Soon","text":"<p>\u2744 Fast Cold-Start Times: To prevent GPUs from idling, Spellbook Serve automatically scales your model to zero when it's not in use and scales up within seconds, even for large foundation models.</p> <p>\ud83d\udcb8 Cost-Optimized: Deploy AI models an order of magnitude cheaper than OpenAI APIs, including cold-start and warm-down times.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"getting_started/","title":"\ud83d\ude80 Getting Started","text":"<p>To start using Spellbook Serve with public inference APIs, simply run the following:</p> Install using pipInstall using conda <pre><code>pip install spellbook-serve\n</code></pre> <pre><code>conda install spellbook-serve -c conda-forge\n</code></pre> <p>Navigate to https://spellbook.scale.com where you will get a Scale API key.</p> <p>With the API key, you can now send requests to Spellbook Serve public inference APIs using the CLI or Python client:</p> Using the CLIUsing the Python Client <pre><code>spellbook-serve generate flan-t5-xxl \\\n    --prompt \"Hello, my name is\"\n    --temperature 0.5\n    --max-tokens 20\n\n# Expected output:\n#\n# Hello, my name is Flan.\n</code></pre> <pre><code>from spellbook_serve_client import Client\nclient = Client()\nresponse = client.generate(\nmodel_name=\"flan-t5-xxl\",\nprompt=\"Hello, my name is\",\ntemperature=0.5,\nmax_tokens=20,\n)\nprint(response)\n</code></pre>"},{"location":"getting_started/#installation-on-kubernetes","title":"\ud83d\udcbb Installation on Kubernetes","text":"<p>To install Spellbook Serve on your infrastructure in Kubernetes, you can use the Helm chart:</p> <pre><code>helm repo add spellbook https://spellbook.github.io/helm-charts\nhelm repo update\nhelm install spellbook-serve spellbook/spellbook-serve\n</code></pre>"},{"location":"api/langchain/","title":"\ud83e\udd9c Langchain","text":"<p>Coming soon!</p>"},{"location":"api/python_client/","title":"Python Client API Reference","text":""},{"location":"api/python_client/#spellbook_serve_client.Client","title":"Client","text":"<pre><code>Client(\nbase_url: Optional[str] = None,\napi_key: Optional[str] = None,\ntimeout: int = 10,\n)\n</code></pre> <p>Client to make calls to a spellbook-serve-client instance</p> Example <pre><code>from spellbook_serve_client import Client\nclient = Client(\"flan-t5-xxl-deepspeed-sync\")\nclient.generate(\"Why is the sky blue?\").outputs[0].text\n# ' Rayleigh scattering'\nresult = \"\"\nfor response in client.generate_stream(\"Why is the sky blue?\"):\nif response.output:\nresult += response.output.text\nresult\n# ' Rayleigh scattering'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>`str`</code> <p>spellbook-serve-client instance base url</p> <code>None</code> <code>api_key</code> <code>`str`</code> <p>API key to use for authentication</p> <code>None</code> <code>timeout</code> <code>`int`</code> <p>Timeout in seconds</p> <code>10</code>"},{"location":"api/python_client/#spellbook_serve_client.client.Client.generate","title":"generate","text":"<pre><code>generate(\nmodel_name: str,\nprompt: str,\nmax_new_tokens: int = 20,\ntemperature: float = 0.2,\n) -&gt; CompletionSyncV1Response\n</code></pre> <p>Given a prompt, generate the following text</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>`str`</code> <p>Model name to use for inference</p> required <code>prompt</code> <code>`str`</code> <p>Input text</p> required <code>max_new_tokens</code> <code>`int`</code> <p>Maximum number of generated tokens</p> <code>20</code> <code>temperature</code> <code>`float`</code> <p>The value used to module the logits distribution.</p> <code>0.2</code> <p>Returns:</p> Name Type Description <code>CompletionSyncV1Response</code> <code>CompletionSyncV1Response</code> <p>generated response</p>"},{"location":"api/python_client/#spellbook_serve_client.client.Client.generate_stream","title":"generate_stream","text":"<pre><code>generate_stream(\nmodel_name: str,\nprompt: str,\nmax_new_tokens: int = 20,\ntemperature: float = 0.2,\n) -&gt; Iterator[CompletionStreamV1Response]\n</code></pre> <p>Given a prompt, generate the following stream of tokens</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>`str`</code> <p>Model name to use for inference</p> required <code>prompt</code> <code>`str`</code> <p>Input text</p> required <code>max_new_tokens</code> <code>`int`</code> <p>Maximum number of generated tokens</p> <code>20</code> <code>temperature</code> <code>`float`</code> <p>The value used to module the logits distribution.</p> <code>0.2</code> <p>Returns:</p> Type Description <code>Iterator[CompletionStreamV1Response]</code> <p>Iterator[CompletionStreamV1Response]: stream of generated tokens</p>"},{"location":"api/python_client/#spellbook_serve_client.CompletionSyncV1Response","title":"CompletionSyncV1Response","text":"<p>         Bases: <code>BaseModel</code></p> <p>Response object for a synchronous prompt completion task.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionSyncV1Response.outputs","title":"outputs  <code>instance-attribute</code>","text":"<pre><code>outputs: List[CompletionOutput]\n</code></pre> <p>List of completion outputs.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionSyncV1Response.status","title":"status  <code>instance-attribute</code>","text":"<pre><code>status: TaskStatus\n</code></pre> <p>Task status.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionSyncV1Response.traceback","title":"traceback  <code>instance-attribute</code> <code>class-attribute</code>","text":"<pre><code>traceback: Optional[str] = None\n</code></pre> <p>Traceback if the task failed.</p>"},{"location":"api/python_client/#spellbook_serve_client.CompletionStreamV1Response","title":"CompletionStreamV1Response","text":"<p>         Bases: <code>BaseModel</code></p> <p>Response object for a stream prompt completion task.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionStreamV1Response.output","title":"output  <code>instance-attribute</code> <code>class-attribute</code>","text":"<pre><code>output: Optional[CompletionStreamOutput] = None\n</code></pre> <p>Completion output.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionStreamV1Response.status","title":"status  <code>instance-attribute</code>","text":"<pre><code>status: TaskStatus\n</code></pre> <p>Task status.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionStreamV1Response.traceback","title":"traceback  <code>instance-attribute</code> <code>class-attribute</code>","text":"<pre><code>traceback: Optional[str] = None\n</code></pre> <p>Traceback if the task failed.</p>"},{"location":"api/python_client/#spellbook_serve_client.CompletionOutput","title":"CompletionOutput","text":"<p>         Bases: <code>BaseModel</code></p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionOutput.num_completion_tokens","title":"num_completion_tokens  <code>instance-attribute</code>","text":"<pre><code>num_completion_tokens: int\n</code></pre> <p>Number of tokens in the completion.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionOutput.num_prompt_tokens","title":"num_prompt_tokens  <code>instance-attribute</code>","text":"<pre><code>num_prompt_tokens: int\n</code></pre> <p>Number of tokens in the prompt.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionOutput.text","title":"text  <code>instance-attribute</code>","text":"<pre><code>text: str\n</code></pre> <p>Text</p>"},{"location":"api/python_client/#spellbook_serve_client.CompletionStreamOutput","title":"CompletionStreamOutput","text":"<p>         Bases: <code>BaseModel</code></p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionStreamOutput.finished","title":"finished  <code>instance-attribute</code>","text":"<pre><code>finished: bool\n</code></pre> <p>Whether the completion is finished.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionStreamOutput.num_completion_tokens","title":"num_completion_tokens  <code>instance-attribute</code> <code>class-attribute</code>","text":"<pre><code>num_completion_tokens: Optional[int] = None\n</code></pre> <p>Number of tokens in the completion.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionStreamOutput.num_prompt_tokens","title":"num_prompt_tokens  <code>instance-attribute</code> <code>class-attribute</code>","text":"<pre><code>num_prompt_tokens: Optional[int] = None\n</code></pre> <p>Number of tokens in the prompt.</p>"},{"location":"api/python_client/#spellbook_serve_client.types.CompletionStreamOutput.text","title":"text  <code>instance-attribute</code>","text":"<pre><code>text: str\n</code></pre> <p>Text</p>"},{"location":"api/python_client/#spellbook_serve_client.TaskStatus","title":"TaskStatus","text":"<p>         Bases: <code>str</code>, <code>Enum</code></p>"}]}