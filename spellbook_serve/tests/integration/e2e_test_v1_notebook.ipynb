{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-To-End Test V1\n",
    "\n",
    "This jupyter notebook complements the existing `e2e_test_v1.py` to help people debug e2e test failures.\n",
    "\n",
    "### Instruction\n",
    "1. First, do `just up` from `models/ml_infra_core` in a terminal. The logs from `launch-gateway-v1-dev` and `launch-service-builder-dev` are available here\n",
    "2. Make a copy of this notebook so we keep the template clean and unchanged\n",
    "3. Just follow the notebook and execute cells that you think are relevant to what you want to test\n",
    "\n",
    "### Tips\n",
    "- To create new cells, select the border of a cell \n",
    "    - press \"b\" to create a cell below the selected cell\n",
    "    - press \"a\" to create a cell above the selected cell\n",
    "- To execute a cell\n",
    "    - press \"Shift+Enter\" to execute the current and move on to the next cell\n",
    "    - press \"Ctrl+Enter\" to execute the current and stay at the current cell (useful if you want to run the same cell multiple times)\n",
    "- Run things on a devbox speeds up the dev/test iteration cycle \n",
    "\n",
    "### Troubleshooting guide\n",
    "#### If you see \n",
    "```bash\n",
    "ml_infra_core-launch-gateway-v1-dev-1       | kubernetes_asyncio.client.exceptions.ApiException: (401)\n",
    "ml_infra_core-launch-gateway-v1-dev-1       | Reason: Unauthorized\n",
    "```\n",
    "- Do `just down` and `just up` again and the issue should be gone.\n",
    "\n",
    "#### If you see \n",
    "```bash\n",
    "ml_infra_core-launch-gateway-v1-dev-1       |   File \"uvloop/loop.pyx\", line 2016, in uvloop.loop.Loop.create_connection\n",
    "ml_infra_core-launch-gateway-v1-dev-1       | OSError: [Errno 113] No route to host\n",
    "```\n",
    "Try creating new endpoints by executing `create_model_endpoint` and then run `delete_existing_endpoints(users=(user,))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2e_test_v1 import *\n",
    "\n",
    "user = \"juitse.hung-e2e-test\"\n",
    "# Options:\n",
    "# - model-endpoint-simple-[a]sync\n",
    "# - model-endpoint-custom-image-[a]sync\n",
    "# - model-endpoint-runnable-image-[a]sync\n",
    "endpoint_name = f\"model-endpoint-simple-sync\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for gateway to be ready before moving on to other cells\n",
    "ensure_gateway_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Delete existing endpoints for the current user\n",
    "delete_existing_endpoints(users=(user,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to create all of the model bundles. This cell takes about 6 seconds to run.\n",
    "get_or_create_model_bundle(CREATE_MODEL_BUNDLE_REQUEST_SIMPLE, user, \"v1\")\n",
    "get_or_create_model_bundle(CREATE_MODEL_BUNDLE_REQUEST_CUSTOM_IMAGE, user, \"v1\")\n",
    "get_or_create_model_bundle(CREATE_MODEL_BUNDLE_REQUEST_RUNNABLE_IMAGE, user, \"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Change the request depending on which endpoint type you want to create\n",
    "Options: \n",
    "- CREATE_[A]SYNC_MODEL_ENDPOINT_REQUEST_SIMPLE\n",
    "- CREATE_[A]SYNC_MODEL_ENDPOINT_REQUEST_CUSTOM_IMAGE\n",
    "- CREATE_[A]SYNC_MODEL_ENDPOINT_REQUEST_RUNNABLE_IMAGE\n",
    "\"\"\"\n",
    "create_model_endpoint(CREATE_SYNC_MODEL_ENDPOINT_REQUEST_SIMPLE, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell till your endpoint is ready\n",
    "endpoints = list_model_endpoints(user)\n",
    "ready_endpoints = [endpoint for endpoint in endpoints if endpoint[\"status\"] == \"READY\"]\n",
    "print(f\"User {user} Current num endpoints: {len(endpoints)}, num ready endpoints: {len(ready_endpoints)}\")\n",
    "print(json.dumps(endpoints, indent=2))\n",
    "assert len(ready_endpoints) >= 1 # TODO: Feel free to manually change how many endpoints you expect to be available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "TODO: Change the update endpoint request depending on the type of endpoint you want to test\n",
    "Options: \n",
    "- UPDATE_MODEL_ENDPOINT_REQUEST_SIMPLE\n",
    "- UPDATE_MODEL_ENDPOINT_REQUEST_CUSTOM_IMAGE\n",
    "- UPDATE_MODEL_ENDPOINT_REQUEST_RUNNABLE_IMAGE\n",
    "Also remember to change the endpoint name to match the endpoint you want to update\n",
    "Options: \n",
    "\"\"\"\n",
    "update_model_endpoint(endpoint_name, UPDATE_MODEL_ENDPOINT_REQUEST_SIMPLE, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See check if the pods are running\n",
    "!kubectl get pods -n scale-deploy -l user_id={user}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this command if you want to see logs from the pod\n",
    "# !kubectl logs -n scale-deploy pods/<pod-name> -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to ssh into the pod, run this command on a separate terminal\n",
    "# kubectl exec -n scale-deploy -it <pod-name> -- /bin/bash\n",
    "# If you want to ssh into a specific container inside the pod, run this command on a separate terminal\n",
    "# kubectl exec -it <pod-name> -c <container-name> -- /bin/bash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For sync endpoint (and all endpoints after LIRA), you can try to forward a port from a pod to your local machine and send request to it\n",
    "You need to **run this command in a separate terminal**\n",
    "\n",
    "`kubectl port-forward -n scale-deploy pod/<pod-name> <local-port>:<remote-port>` \n",
    "\n",
    "E.g. `kubectl port-forward -n scale-deploy pod/<pod-name> 5000:5000` \n",
    "\n",
    "Note: This is a bit flaky and doesn't always work. But when I works it's really helpful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only works if you've run the port forwrading command in the previous cell\n",
    "response = requests.post(\n",
    "    f\"http://localhost:5000/predict\",\n",
    "    json={\n",
    "        \"args\": {\"y\": 1},\n",
    "        \"url\": None,\n",
    "        \"return_pickled\": False,\n",
    "    },\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    auth=requests.auth.HTTPBasicAuth(\"test-user-id\", \"\"),\n",
    "    timeout=DEFAULT_NETWORK_TIMEOUT_SEC,\n",
    ")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "launch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
